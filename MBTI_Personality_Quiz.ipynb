{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LbUAtY04jhnI"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1Fmw4Wak6Yw"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Configure with your API key\n",
        "genai.configure(api_key='replcae your orginal API key here')\n",
        "# Initialize the model\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "fQsyry1slD3n",
        "outputId": "b8834a38-0ab7-4d1b-b6ce-693964e3be8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available models:\n",
            "- models/gemini-1.0-pro-vision-latest\n",
            "- models/gemini-pro-vision\n",
            "- models/gemini-1.5-pro-latest\n",
            "- models/gemini-1.5-pro-001\n",
            "- models/gemini-1.5-pro-002\n",
            "- models/gemini-1.5-pro\n",
            "- models/gemini-1.5-flash-latest\n",
            "- models/gemini-1.5-flash-001\n",
            "- models/gemini-1.5-flash-001-tuning\n",
            "- models/gemini-1.5-flash\n",
            "- models/gemini-1.5-flash-002\n",
            "- models/gemini-1.5-flash-8b\n",
            "- models/gemini-1.5-flash-8b-001\n",
            "- models/gemini-1.5-flash-8b-latest\n",
            "- models/gemini-1.5-flash-8b-exp-0827\n",
            "- models/gemini-1.5-flash-8b-exp-0924\n",
            "- models/gemini-2.5-pro-exp-03-25\n",
            "- models/gemini-2.0-flash-exp\n",
            "- models/gemini-2.0-flash\n",
            "- models/gemini-2.0-flash-001\n",
            "- models/gemini-2.0-flash-exp-image-generation\n",
            "- models/gemini-2.0-flash-lite-001\n",
            "- models/gemini-2.0-flash-lite\n",
            "- models/gemini-2.0-flash-lite-preview-02-05\n",
            "- models/gemini-2.0-flash-lite-preview\n",
            "- models/gemini-2.0-pro-exp\n",
            "- models/gemini-2.0-pro-exp-02-05\n",
            "- models/gemini-exp-1206\n",
            "- models/gemini-2.0-flash-thinking-exp-01-21\n",
            "- models/gemini-2.0-flash-thinking-exp\n",
            "- models/gemini-2.0-flash-thinking-exp-1219\n",
            "- models/learnlm-1.5-pro-experimental\n",
            "- models/gemma-3-27b-it\n",
            "Successfully generated example 1: INTJ\n",
            "Response: Planning.  Spontaneity introduces unacceptable variables.\n",
            "\n",
            "\n",
            "Successfully generated example 2: ENFP\n",
            "Response: Ooh, both! Logic's cool, but emotions are like, *sparkly* guideposts, ya know? ‚ú®\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 555.19ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error generating example 3: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Dataset generation complete!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "\n",
        "# Configure with your API key\n",
        "genai.configure(api_key='reaplace your orginal API key here')\n",
        "# Check available models\n",
        "print(\"Available models:\")\n",
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(f\"- {m.name}\")\n",
        "\n",
        "# Initialize the correct model - UPDATED MODEL NAME\n",
        "model = genai.GenerativeModel('gemini-1.5-pro-latest')  # Updated to current model name\n",
        "\n",
        "mbti_types = [\"INTJ\", \"ENFP\", \"ISTJ\"]\n",
        "questions = [\n",
        "    \"Do you prefer planning or spontaneity?\",\n",
        "    \"Are you more logical or emotional in decisions?\",\n",
        "    \"Do you enjoy social gatherings?\"\n",
        "]\n",
        "\n",
        "# Generate and save examples\n",
        "with open(\"gemini_mbti_dataset.jsonl\", \"w\") as f:\n",
        "    for i in range(3):\n",
        "        try:\n",
        "            response = model.generate_content(\n",
        "                f\"Answer this question as if you're an {mbti_types[i]} personality type: {questions[i]}. Keep the answer under 15 words.\"\n",
        "            )\n",
        "\n",
        "            data = {\n",
        "                \"prompt\": f\"Q: {questions[i]}\\nA: {response.text}\",\n",
        "                \"completion\": f\" {mbti_types[i]}\"\n",
        "            }\n",
        "            f.write(json.dumps(data) + \"\\n\")\n",
        "            print(f\"Successfully generated example {i+1}: {mbti_types[i]}\")\n",
        "            print(f\"Response: {response.text}\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating example {i+1}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "print(\"Dataset generation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hYyGN-gCoFhv"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvkNsSX2onsg",
        "outputId": "6e8a7efe-e7c0-407b-876c-39be4eac1470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"prompt\": \"Q: Do you prefer planning or spontaneity?\\nA: Planning.  Spontaneity introduces unacceptable variables.\\n\", \"completion\": \" INTJ\"}\n",
            "{\"prompt\": \"Q: Are you more logical or emotional in decisions?\\nA: Ooh, both! Logic's cool, but emotions are like, *sparkly* guideposts, ya know? \\u2728\\n\", \"completion\": \" ENFP\"}\n"
          ]
        }
      ],
      "source": [
        "!head gemini_mbti_dataset.jsonl  # View first examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "PbE98jWTzKZH",
        "outputId": "7ce7c7d1-2525-40a3-e178-fa6073508531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üåü MBTI Personality Quiz üåü\n",
            "Answer these questions to discover your personality type!\n",
            "\n",
            "\n",
            "Question 1/4: Do you prefer (1) being alone or (2) social gatherings? (Enter 1 or 2)\n",
            "> 1\n",
            "\n",
            "Question 2/4: When learning, do you prefer (1) concrete facts or (2) big-picture concepts? (Enter 1 or 2)\n",
            "> 2\n",
            "\n",
            "Question 3/4: When making decisions, do you rely more on (1) logic or (2) feelings? (Enter 1 or 2)\n",
            "> 2\n",
            "\n",
            "Question 4/4: Do you prefer (1) planned schedules or (2) spontaneous activities? (Enter 1 or 2)\n",
            "> 2\n",
            "\n",
            "========================================\n",
            "Your MBTI Personality Type: ENFP\n",
            "Description: This individual displays a mix of introversion and extroversion, favoring intuition, feeling, and perceiving, suggesting a preference for imaginative ideas, emotional connections, and adaptable spontaneity.\n",
            "\n",
            "========================================\n",
            "\n",
            "üîç What this means:\n",
            "* **Enthusiastic Imaginers:** ENFPs are highly creative, energetic, and driven by their values. They see potential everywhere and love brainstorming new ideas and possibilities.\n",
            "\n",
            "* **Passionate Connectors:** They are warmly empathetic, prioritize authentic connections, and excel at understanding and motivating others. They strive to create a positive impact on the people around them.\n",
            "\n",
            "* **Free-Spirited Explorers:** ENFPs crave novelty and embrace change.  They are curious, adaptable, and prefer to keep their options open rather than be confined by rigid plans.\n",
            "\n",
            "\n",
            "Would you like to retake the quiz? (y/n): n\n",
            "Thanks for taking the quiz!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "\n",
        "# Configure with your API key\n",
        "genai.configure(api_key='AIzaSyAVZIR7-P_ILInFazdvydINXVFCUds01jQ')\n",
        "\n",
        "# Initialize the model\n",
        "model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "\n",
        "def interactive_quiz():\n",
        "    print(\"\\nüåü MBTI Personality Quiz üåü\")\n",
        "    print(\"Answer these questions to discover your personality type!\\n\")\n",
        "\n",
        "    # Define quiz questions\n",
        "    questions = [\n",
        "        \"Do you prefer (1) being alone or (2) social gatherings? (Enter 1 or 2)\",\n",
        "        \"When learning, do you prefer (1) concrete facts or (2) big-picture concepts? (Enter 1 or 2)\",\n",
        "        \"When making decisions, do you rely more on (1) logic or (2) feelings? (Enter 1 or 2)\",\n",
        "        \"Do you prefer (1) planned schedules or (2) spontaneous activities? (Enter 1 or 2)\"\n",
        "    ]\n",
        "\n",
        "    answers = []\n",
        "\n",
        "    # Ask questions\n",
        "    for i, question in enumerate(questions):\n",
        "        while True:\n",
        "            answer = input(f\"\\nQuestion {i+1}/{len(questions)}: {question}\\n> \")\n",
        "            if answer in ['1', '2']:\n",
        "                answers.append(answer)\n",
        "                break\n",
        "            else:\n",
        "                print(\"Please enter either 1 or 2\")\n",
        "\n",
        "    # Analyze answers\n",
        "    answer_map = {\n",
        "        '1': \"prefers being alone, concrete facts, logic, planned schedules\",\n",
        "        '2': \"enjoys social gatherings, big-picture concepts, feelings, spontaneous activities\"\n",
        "    }\n",
        "\n",
        "    analysis_prompt = f\"\"\"Analyze these answers to determine the MBTI type:\n",
        "    {', '.join([answer_map[a] for a in answers])}\n",
        "\n",
        "    Respond ONLY with the 4-letter MBTI type (e.g., INTJ) and a 1-sentence description.\n",
        "    Format: TYPE|Description\"\"\"\n",
        "\n",
        "    response = model.generate_content(analysis_prompt)\n",
        "    result = response.text.split('|')\n",
        "\n",
        "    # Display result\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"Your MBTI Personality Type: {result[0]}\")\n",
        "    print(f\"Description: {result[1]}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Show type meaning\n",
        "    type_info = model.generate_content(\n",
        "        f\"Explain the {result[0]} personality type in 3 bullet points\")\n",
        "    print(\"\\nüîç What this means:\")\n",
        "    print(type_info.text)\n",
        "\n",
        "# Run the quiz\n",
        "interactive_quiz()\n",
        "\n",
        "# Option to retake\n",
        "while True:\n",
        "    retake = input(\"\\nWould you like to retake the quiz? (y/n): \").lower()\n",
        "    if retake == 'y':\n",
        "        interactive_quiz()\n",
        "    else:\n",
        "        print(\"Thanks for taking the quiz!\")\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
